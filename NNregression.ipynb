{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NNregression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRIPhL05QdY5",
        "colab_type": "text"
      },
      "source": [
        "#Rede Neural para regressão - tf.keras.Sequential "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVmEB0uARdm4",
        "colab_type": "text"
      },
      "source": [
        "Neste exemplo vamos utilizar as bilbiotecas Numpy e Tensorflow para manipulação de tensores e Pandas para manipulação de dados estruturados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcjr8kau-zP-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcYVhA6sDcdS",
        "colab_type": "text"
      },
      "source": [
        "longitude,latitude,housing_median_age,total_rooms,total_bedrooms,population,households,median_income,median_house_value,ocean_proximity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1GAPqJERypM",
        "colab_type": "text"
      },
      "source": [
        "Neste exemplo vamos simular como aplicar uma regressão em um grande volume de dados. Sendo assim, para carregar nossos dados, vamos utilizar uma função para gerar batches, processá-los durante a leitura e criar um objeto do tipo dataset.\n",
        "\n",
        "A célula a seguir é apenas auxiliar. Em ambientes com grande volume de dados não é possível carregar tudo em memória. Nesta célula estão as informações que seriam extraídas previamente da fote dos dados.\n",
        "\n",
        "As colunas com dados numéricos e categóricos são distintas para agilizar o pré-processamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDHudu92NiXR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUMERIC_COLUMNS = ['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
        "       'total_bedrooms', 'population', 'households', 'median_income']\n",
        "\n",
        "CATEGORICAL_COLUMNS = ['ocean_proximity']\n",
        "VALUE_COMLUMN = 'median_house_value'\n",
        "\n",
        "CATEGORIES = {\n",
        "    'ocean_proximity': ['<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN']\n",
        "}\n",
        "\n",
        "data_example = pd.read_csv('housing.csv')\n",
        "desc = data_example[NUMERIC_COLUMNS].describe()\n",
        "MEAN = np.array(desc.T['mean'])\n",
        "STD = np.array(desc.T['std'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBCljfc0Tsg8",
        "colab_type": "code",
        "outputId": "27e2da9a-9f5f-4d8a-bafa-fe1a9236ed34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data_example.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "      <th>ocean_proximity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-122.23</td>\n",
              "      <td>37.88</td>\n",
              "      <td>41.0</td>\n",
              "      <td>880.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>322.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>8.3252</td>\n",
              "      <td>452600.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-122.22</td>\n",
              "      <td>37.86</td>\n",
              "      <td>21.0</td>\n",
              "      <td>7099.0</td>\n",
              "      <td>1106.0</td>\n",
              "      <td>2401.0</td>\n",
              "      <td>1138.0</td>\n",
              "      <td>8.3014</td>\n",
              "      <td>358500.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-122.24</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1467.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>496.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>7.2574</td>\n",
              "      <td>352100.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-122.25</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1274.0</td>\n",
              "      <td>235.0</td>\n",
              "      <td>558.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>5.6431</td>\n",
              "      <td>341300.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-122.25</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1627.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>565.0</td>\n",
              "      <td>259.0</td>\n",
              "      <td>3.8462</td>\n",
              "      <td>342200.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   longitude  latitude  ...  median_house_value  ocean_proximity\n",
              "0    -122.23     37.88  ...            452600.0         NEAR BAY\n",
              "1    -122.22     37.86  ...            358500.0         NEAR BAY\n",
              "2    -122.24     37.85  ...            352100.0         NEAR BAY\n",
              "3    -122.25     37.85  ...            341300.0         NEAR BAY\n",
              "4    -122.25     37.85  ...            342200.0         NEAR BAY\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWoaAW5hSzHC",
        "colab_type": "text"
      },
      "source": [
        "## Modelo de Regressão"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e5C1HjrS9yD",
        "colab_type": "text"
      },
      "source": [
        "### Carregamento de dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BOoRnyLU1eW",
        "colab_type": "text"
      },
      "source": [
        "A função a seguir nos auxiliará a visulizar os batches carregados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9U6uqkFTza3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_batch(dataset):\n",
        "  for batch, label in dataset.take(1):\n",
        "    for key, value in batch.items():\n",
        "      print(\"{:20s}: {}\".format(key,value.numpy()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DY-KEewaTI9u",
        "colab_type": "text"
      },
      "source": [
        "Vamos inciar criando um método para fazer a leitura dos dados de um csv e criar um objeto de dataset do tensorflow. Nela definimos o tamanho do batch, os valores padrões para dados ausentes e qual campo representa nossa variável dependente (Y)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCTnromhStvf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dataset(file_path, batch_size):\n",
        "  dataset = tf.data.experimental.make_csv_dataset(\n",
        "      file_path,\n",
        "      batch_size=batch_size, \n",
        "      label_name=VALUE_COMLUMN,\n",
        "      na_value='0',\n",
        "      num_epochs=1,\n",
        "      ignore_errors=True)\n",
        "  return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Sa1wGsbTQxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_train_data = get_dataset('housing.csv', 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3nz3_mAX6ko",
        "colab_type": "text"
      },
      "source": [
        "Enquanto não houver requisição de leitura dos dados, e.g. *take(1)*, eles não são carregados em memória e o objeto permanece vazio, mantendo apenas a estrutura do dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugyjmEptT2hN",
        "colab_type": "code",
        "outputId": "209dc77f-69eb-45d1-8940-45ec6addec1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "raw_train_data"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: (OrderedDict([(longitude, (None,)), (latitude, (None,)), (housing_median_age, (None,)), (total_rooms, (None,)), (total_bedrooms, (None,)), (population, (None,)), (households, (None,)), (median_income, (None,)), (ocean_proximity, (None,))]), (None,)), types: (OrderedDict([(longitude, tf.float32), (latitude, tf.float32), (housing_median_age, tf.float32), (total_rooms, tf.float32), (total_bedrooms, tf.float32), (population, tf.float32), (households, tf.float32), (median_income, tf.float32), (ocean_proximity, tf.string)]), tf.float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7O5udV2BV5Du",
        "colab_type": "text"
      },
      "source": [
        "Com o método *show_dataset* podemos visualizar o batch. Apenas um batch é carregado por vez."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVSc8KFkUCHs",
        "colab_type": "code",
        "outputId": "41c897e5-64dc-4fcb-c02a-39bd64f17b75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "show_batch(raw_train_data)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "longitude           : [-118.23 -117.98 -118.45 -119.81 -122.3  -119.82 -118.05 -118.96 -119.79\n",
            " -122.1 ]\n",
            "latitude            : [34.13 33.92 34.02 36.83 38.3  36.78 34.04 35.38 36.79 37.63]\n",
            "housing_median_age  : [47. 27. 41. 19. 21. 36. 33. 41. 19. 18.]\n",
            "total_rooms         : [1162. 3700. 2956. 6789. 1108. 1582. 1348. 2417. 1524. 9963.]\n",
            "total_bedrooms      : [ 235.    0.  700. 1200.  269.  313.    0.  435.  448. 2031.]\n",
            "population          : [ 781. 1793. 1212. 2325.  524.  761. 1098.  973.  960. 5613.]\n",
            "households          : [ 268.  552.  645. 1109.  274.  318.  257.  406.  386. 1946.]\n",
            "median_income       : [4.6528 5.3668 3.4583 4.049  2.7619 2.6055 4.2917 3.0568 1.5122 3.8171]\n",
            "ocean_proximity     : [b'<1H OCEAN' b'<1H OCEAN' b'<1H OCEAN' b'INLAND' b'NEAR BAY' b'INLAND'\n",
            " b'<1H OCEAN' b'INLAND' b'INLAND' b'NEAR BAY']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yILa9LoTYm-3",
        "colab_type": "text"
      },
      "source": [
        "Vamos criar o método o objeto *PackNumericFeatures* para criar um tensor que contenha apenas as características numéricas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHG_HmcPScyn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PackNumericFeatures(object):\n",
        "  def __init__(self, names):\n",
        "    self.names = names\n",
        "\n",
        "  def __call__(self, features, labels):\n",
        "    numeric_features = [features.pop(name) for name in self.names]\n",
        "    numeric_features = [tf.cast(feat, tf.float32) for feat in numeric_features]\n",
        "    numeric_features = tf.stack(numeric_features, axis=-1)\n",
        "    features['numeric'] = numeric_features\n",
        "\n",
        "    return features, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWhAnGdaTO8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = raw_train_data.map(\n",
        "    PackNumericFeatures(NUMERIC_COLUMNS))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-M8Nh9ZUQ7O",
        "colab_type": "code",
        "outputId": "bcf0d5c3-44ed-49da-d289-6fc7d48b7b0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "show_batch(train_data)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ocean_proximity     : [b'<1H OCEAN' b'INLAND' b'<1H OCEAN' b'INLAND' b'INLAND' b'<1H OCEAN'\n",
            " b'<1H OCEAN' b'<1H OCEAN' b'<1H OCEAN' b'INLAND']\n",
            "numeric             : [[-1.1829e+02  3.3990e+01  4.3000e+01  1.9020e+03  3.9800e+02  1.1530e+03\n",
            "   3.6300e+02  1.9375e+00]\n",
            " [-1.1974e+02  3.6780e+01  2.7000e+01  4.0490e+03  9.4700e+02  2.2540e+03\n",
            "   8.8200e+02  2.2467e+00]\n",
            " [-1.1837e+02  3.3870e+01  1.9000e+01  7.5700e+02  1.4800e+02  3.6100e+02\n",
            "   1.4100e+02  6.0200e+00]\n",
            " [-1.1969e+02  3.6810e+01  1.5000e+01  2.8920e+03  4.9600e+02  1.6340e+03\n",
            "   5.0100e+02  4.4934e+00]\n",
            " [-1.1969e+02  3.6800e+01  3.1000e+01  2.5760e+03  4.5800e+02  1.3060e+03\n",
            "   4.1800e+02  3.2813e+00]\n",
            " [-1.1832e+02  3.3940e+01  3.7000e+01  2.7400e+03  5.0400e+02  1.4680e+03\n",
            "   4.7900e+02  4.5368e+00]\n",
            " [-1.1817e+02  3.3920e+01  4.3000e+01  2.0990e+03  3.9800e+02  1.2760e+03\n",
            "   3.8700e+02  3.1528e+00]\n",
            " [-1.1847e+02  3.4010e+01  4.4000e+01  2.1750e+03  4.7500e+02  1.0190e+03\n",
            "   4.4800e+02  4.7930e+00]\n",
            " [-1.2402e+02  4.0720e+01  2.8000e+01  3.5130e+03  6.3400e+02  1.6580e+03\n",
            "   5.9800e+02  3.8095e+00]\n",
            " [-1.1773e+02  3.4070e+01  3.3000e+01  1.0250e+03  2.6100e+02  8.5400e+02\n",
            "   2.6900e+02  2.2596e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtU3ZvEecAwc",
        "colab_type": "text"
      },
      "source": [
        "Para obtermos um treino mais estável e melhor performance ao aplicar o gradiente descendente, recomenda-se normalizar os dados. Uma forma é mantes média 0 e desvio padrão 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQrDHDGuVe9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize_numeric_data(X):\n",
        "  return (X-MEAN)/STD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9hmTX1DcldH",
        "colab_type": "text"
      },
      "source": [
        "Um dos objetos que possibilitam a manipulação de dados entre a fonte crua e a entrada em modelos no tensorflow "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahwP1m4ldOqz",
        "colab_type": "text"
      },
      "source": [
        "*tf.feature_column.numeric_column* nos possibilitará manipulações de dados numéricos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5NJWTJjWE4M",
        "colab_type": "code",
        "outputId": "3384ecc7-bbc3-459b-bbd6-ffebb900ab1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "numeric_column = tf.feature_column.numeric_column('numeric', normalizer_fn=normalize_numeric_data, shape=[len(NUMERIC_COLUMNS)])\n",
        "numeric_columns = [numeric_column]\n",
        "numeric_column"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NumericColumn(key='numeric', shape=(8,), default_value=None, dtype=tf.float32, normalizer_fn=<function normalize_numeric_data at 0x7fa2e59d9b70>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KMIEZP8jbZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example_batch, labels = next(iter(train_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X055JheTnjgH",
        "colab_type": "code",
        "outputId": "4005a23c-84ae-468b-86cc-3c5a19ca358c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "example_batch"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('ocean_proximity', <tf.Tensor: shape=(10,), dtype=string, numpy=\n",
              "              array([b'NEAR BAY', b'NEAR BAY', b'<1H OCEAN', b'NEAR BAY', b'NEAR BAY',\n",
              "                     b'<1H OCEAN', b'NEAR BAY', b'<1H OCEAN', b'NEAR BAY', b'<1H OCEAN'],\n",
              "                    dtype=object)>),\n",
              "             ('numeric', <tf.Tensor: shape=(10, 8), dtype=float32, numpy=\n",
              "              array([[-1.2203e+02,  3.7940e+01,  2.1000e+01,  5.5410e+03,  7.7600e+02,\n",
              "                       2.2140e+03,  7.3700e+02,  5.5777e+00],\n",
              "                     [-1.2258e+02,  3.7980e+01,  5.2000e+01,  3.6750e+03,  6.4900e+02,\n",
              "                       1.5530e+03,  6.3900e+02,  4.6905e+00],\n",
              "                     [-1.1802e+02,  3.3930e+01,  3.5000e+01,  2.4000e+03,  3.9800e+02,\n",
              "                       1.2180e+03,  4.0800e+02,  4.1312e+00],\n",
              "                     [-1.2209e+02,  3.7650e+01,  3.5000e+01,  1.1300e+03,  1.9200e+02,\n",
              "                       5.4300e+02,  1.8400e+02,  4.3897e+00],\n",
              "                     [-1.2231e+02,  3.8300e+01,  4.5000e+01,  3.0230e+03,  6.5900e+02,\n",
              "                       1.7890e+03,  6.5700e+02,  3.6039e+00],\n",
              "                     [-1.1835e+02,  3.4270e+01,  3.2000e+01,  6.0400e+02,  1.0800e+02,\n",
              "                       3.1400e+02,  1.1300e+02,  6.2037e+00],\n",
              "                     [-1.2224e+02,  3.7820e+01,  5.2000e+01,  3.4810e+03,  7.5100e+02,\n",
              "                       1.4440e+03,  7.1800e+02,  3.9000e+00],\n",
              "                     [-1.1823e+02,  3.3990e+01,  5.0000e+00,  7.0600e+02,  2.0300e+02,\n",
              "                       8.3900e+02,  1.9900e+02,  4.5208e+00],\n",
              "                     [-1.2217e+02,  3.7730e+01,  5.2000e+01,  1.5550e+03,  2.8900e+02,\n",
              "                       6.2000e+02,  2.9200e+02,  3.7159e+00],\n",
              "                     [-1.1836e+02,  3.3860e+01,  3.4000e+01,  1.8650e+03,  3.4500e+02,\n",
              "                       9.6300e+02,  3.0200e+02,  5.5430e+00]], dtype=float32)>)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6lHFRs0nP-0",
        "colab_type": "text"
      },
      "source": [
        "A saída da camada *numeric_layer* será um tensor com os dados já normalizados\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUfQtgtoZbJC",
        "colab_type": "code",
        "outputId": "1731e980-1eab-4ae8-907a-9ebfb86c54ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "numeric_layer = tf.keras.layers.DenseFeatures(numeric_columns)\n",
        "numeric_layer(example_batch).numpy()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.6388040e+00,  1.3578739e+00, -6.4357263e-01,  1.2801857e+00,\n",
              "         5.3061253e-01,  6.7473537e-01,  5.9384203e-01,  9.3965578e-01],\n",
              "       [-1.9376200e+00,  1.3773947e+00,  1.8631470e+00,  4.5700023e-01,\n",
              "         2.4051251e-01,  9.6183583e-02,  3.4522760e-01,  4.6987909e-01],\n",
              "       [ 5.3982520e-01, -5.9903520e-01,  4.8849431e-01, -1.0546570e-01,\n",
              "        -3.3283484e-01, -1.9703102e-01, -2.4079211e-01,  1.7372717e-01],\n",
              "       [-1.6714005e+00,  1.2163532e+00,  4.8849431e-01, -6.6572589e-01,\n",
              "        -8.0339080e-01, -7.8783655e-01, -8.0905366e-01,  3.1060418e-01],\n",
              "       [-1.7909271e+00,  1.5335568e+00,  1.2971135e+00,  1.6937059e-01,\n",
              "         2.6335502e-01,  3.0274668e-01,  3.9089146e-01, -1.0548057e-01],\n",
              "       [ 3.6053565e-01, -4.3311256e-01,  2.4590854e-01, -8.9777064e-01,\n",
              "        -9.9526805e-01, -9.8827279e-01, -9.8917228e-01,  1.2711257e+00],\n",
              "       [-1.7528963e+00,  1.2993135e+00,  1.8631470e+00,  3.7141716e-01,\n",
              "         4.7350624e-01,  7.7942823e-04,  5.4564124e-01,  5.1305838e-02],\n",
              "       [ 4.2572883e-01, -5.6975406e-01, -1.9373634e+00, -8.5277337e-01,\n",
              "        -7.7826405e-01, -5.2875739e-01, -7.7100044e-01,  3.8002232e-01],\n",
              "       [-1.7148654e+00,  1.2553928e+00,  1.8631470e+00, -4.7823724e-01,\n",
              "        -5.8181834e-01, -7.2044092e-01, -5.3507042e-01, -4.6176050e-02],\n",
              "       [ 3.5510150e-01, -6.3319558e-01,  4.0763238e-01, -3.4148082e-01,\n",
              "        -4.5390022e-01, -4.2022422e-01, -5.0970161e-01,  9.2128205e-01]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CQUxGkll89R",
        "colab_type": "text"
      },
      "source": [
        "Da mesma forma que pre-processamos os dados numéricos, é preciso realizar alguns procimentos nos dados categóricos. O principal deles é criar uma representação numérica para eles. Em nosso caso, vamos criar um one-hot-encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wmHi08ImhTV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  CATEGORIES: dicionário que mapeia a colunas numéricas a todos os valores que ela pode possuir\n",
        "categorical_columns = []\n",
        "for feature, vocab in CATEGORIES.items():\n",
        "  cat_col = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "        key=feature, vocabulary_list=vocab)\n",
        "  categorical_columns.append(tf.feature_column.indicator_column(cat_col))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MLExLWIm0OY",
        "colab_type": "code",
        "outputId": "2ca96436-b026-4b86-9e20-63fbae6da01f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "categorical_columns"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='ocean_proximity', vocabulary_list=('<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN'), dtype=tf.string, default_value=-1, num_oov_buckets=0))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5E-EFmGOgRKz",
        "colab_type": "text"
      },
      "source": [
        "Assim como a *numeric_layer* criada, a saída da *categorical_layer* será um tensor com os dados processados "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKSwEmQFm6C_",
        "colab_type": "code",
        "outputId": "92c2e40f-d464-4730-8102-aec31b2ab8d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "categorical_layer = tf.keras.layers.DenseFeatures(categorical_columns)\n",
        "print(categorical_layer(example_batch).numpy())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nl_OCWqpg-Yj",
        "colab_type": "text"
      },
      "source": [
        "Agora criamos uma última camada de pré-processamento, que será a composição da numérica e categórica. A saída dessa camada, será a entrada para o modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evbCo4ZbneRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocessing_layer = tf.keras.layers.DenseFeatures(categorical_columns+numeric_columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Iq-fuJunvQc",
        "colab_type": "code",
        "outputId": "c3e42af2-e186-47cc-b9af-d98144f2881e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "print(preprocessing_layer(example_batch).numpy())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-1.6388040e+00  1.3578739e+00 -6.4357263e-01  1.2801857e+00\n",
            "   5.3061253e-01  6.7473537e-01  5.9384203e-01  9.3965578e-01\n",
            "   0.0000000e+00  0.0000000e+00  0.0000000e+00  1.0000000e+00\n",
            "   0.0000000e+00]\n",
            " [-1.9376200e+00  1.3773947e+00  1.8631470e+00  4.5700023e-01\n",
            "   2.4051251e-01  9.6183583e-02  3.4522760e-01  4.6987909e-01\n",
            "   0.0000000e+00  0.0000000e+00  0.0000000e+00  1.0000000e+00\n",
            "   0.0000000e+00]\n",
            " [ 5.3982520e-01 -5.9903520e-01  4.8849431e-01 -1.0546570e-01\n",
            "  -3.3283484e-01 -1.9703102e-01 -2.4079211e-01  1.7372717e-01\n",
            "   1.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
            "   0.0000000e+00]\n",
            " [-1.6714005e+00  1.2163532e+00  4.8849431e-01 -6.6572589e-01\n",
            "  -8.0339080e-01 -7.8783655e-01 -8.0905366e-01  3.1060418e-01\n",
            "   0.0000000e+00  0.0000000e+00  0.0000000e+00  1.0000000e+00\n",
            "   0.0000000e+00]\n",
            " [-1.7909271e+00  1.5335568e+00  1.2971135e+00  1.6937059e-01\n",
            "   2.6335502e-01  3.0274668e-01  3.9089146e-01 -1.0548057e-01\n",
            "   0.0000000e+00  0.0000000e+00  0.0000000e+00  1.0000000e+00\n",
            "   0.0000000e+00]\n",
            " [ 3.6053565e-01 -4.3311256e-01  2.4590854e-01 -8.9777064e-01\n",
            "  -9.9526805e-01 -9.8827279e-01 -9.8917228e-01  1.2711257e+00\n",
            "   1.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
            "   0.0000000e+00]\n",
            " [-1.7528963e+00  1.2993135e+00  1.8631470e+00  3.7141716e-01\n",
            "   4.7350624e-01  7.7942823e-04  5.4564124e-01  5.1305838e-02\n",
            "   0.0000000e+00  0.0000000e+00  0.0000000e+00  1.0000000e+00\n",
            "   0.0000000e+00]\n",
            " [ 4.2572883e-01 -5.6975406e-01 -1.9373634e+00 -8.5277337e-01\n",
            "  -7.7826405e-01 -5.2875739e-01 -7.7100044e-01  3.8002232e-01\n",
            "   1.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
            "   0.0000000e+00]\n",
            " [-1.7148654e+00  1.2553928e+00  1.8631470e+00 -4.7823724e-01\n",
            "  -5.8181834e-01 -7.2044092e-01 -5.3507042e-01 -4.6176050e-02\n",
            "   0.0000000e+00  0.0000000e+00  0.0000000e+00  1.0000000e+00\n",
            "   0.0000000e+00]\n",
            " [ 3.5510150e-01 -6.3319558e-01  4.0763238e-01 -3.4148082e-01\n",
            "  -4.5390022e-01 -4.2022422e-01 -5.0970161e-01  9.2128205e-01\n",
            "   1.0000000e+00  0.0000000e+00  0.0000000e+00  0.0000000e+00\n",
            "   0.0000000e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9LUw4HmqUVj",
        "colab_type": "text"
      },
      "source": [
        "## Criando o modelo com tf.keras.Sequential"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lo2gu2iknyBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(preprocessing_layer):\n",
        "  model = tf.keras.Sequential([\n",
        "    preprocessing_layer,\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(1),\n",
        "  ])\n",
        "\n",
        "  model.compile(\n",
        "      loss=tf.keras.losses.MeanSquaredError(),\n",
        "      optimizer='adam',\n",
        "      metrics=['mse'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyrT5iOCqZfD",
        "colab_type": "code",
        "outputId": "0cd9acae-812a-4933-e534-e41d05716d34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "model = create_model(preprocessing_layer)\n",
        "model.fit(train_data, epochs=10)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2064/2064 [==============================] - 3s 2ms/step - loss: 26174494720.0000 - mse: 26174494720.0000\n",
            "Epoch 2/10\n",
            "2064/2064 [==============================] - 3s 2ms/step - loss: 5653015040.0000 - mse: 5653015040.0000\n",
            "Epoch 3/10\n",
            "2064/2064 [==============================] - 3s 2ms/step - loss: 4896101376.0000 - mse: 4896101376.0000\n",
            "Epoch 4/10\n",
            "2064/2064 [==============================] - 3s 2ms/step - loss: 4718416896.0000 - mse: 4718416896.0000\n",
            "Epoch 5/10\n",
            "2064/2064 [==============================] - 3s 2ms/step - loss: 4648616448.0000 - mse: 4648616448.0000\n",
            "Epoch 6/10\n",
            "2064/2064 [==============================] - 3s 2ms/step - loss: 4594756608.0000 - mse: 4594756608.0000\n",
            "Epoch 7/10\n",
            "2064/2064 [==============================] - 3s 2ms/step - loss: 4567065600.0000 - mse: 4567065600.0000\n",
            "Epoch 8/10\n",
            "2064/2064 [==============================] - 3s 2ms/step - loss: 4533727232.0000 - mse: 4533727232.0000\n",
            "Epoch 9/10\n",
            "2064/2064 [==============================] - 3s 2ms/step - loss: 4510978560.0000 - mse: 4510978560.0000\n",
            "Epoch 10/10\n",
            "2064/2064 [==============================] - 3s 2ms/step - loss: 4480894976.0000 - mse: 4480894976.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa2e594d898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HebFmaU2q83I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model.predict(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkFKBz9HrAI3",
        "colab_type": "code",
        "outputId": "cec1d4da-b74a-44f6-c76e-f81e60f3cecf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred[0]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([377961.66], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7YH8VREs8jF",
        "colab_type": "code",
        "outputId": "e6d3ad91-f215-4a43-a931-1286b4ac9c40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_features_2 (DenseFeatu multiple                  0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  1792      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  16512     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  129       \n",
            "=================================================================\n",
            "Total params: 18,433\n",
            "Trainable params: 18,433\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJRSAhGzuJbl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}